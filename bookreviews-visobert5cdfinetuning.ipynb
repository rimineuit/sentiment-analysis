{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10215861,"sourceType":"datasetVersion","datasetId":6312613},{"sourceId":10219560,"sourceType":"datasetVersion","datasetId":6317448}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, classification_report\nimport torch\nfrom torch.utils.data import Dataset\nimport pandas as pd\nimport numpy as np\nfrom typing import *\nimport json\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:19:02.407473Z","iopub.execute_input":"2024-12-16T21:19:02.407702Z","iopub.status.idle":"2024-12-16T21:19:07.615956Z","shell.execute_reply.started":"2024-12-16T21:19:02.407678Z","shell.execute_reply":"2024-12-16T21:19:07.615277Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom transformers import AutoTokenizer\n\nclass BookReviews(Dataset):\n    def __init__(self, path: str, tokenizer, max_length=512):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n        # Load data\n        data = pd.read_json(path, orient=\"records\", lines=True)\n        self.sentences = data[\"review\"].tolist()\n        self.labels = data[\"sentiment\"].tolist()\n\n        # Create label-to-index mapping\n        labels_unique = set(self.labels)\n        self.labels_to_idx = {label: i for i, label in enumerate(labels_unique)}\n\n    def __getitem__(self, idx):\n        # Tokenize sentence\n        encoded = self.tokenizer(\n            self.sentences[idx],\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n        \n        # Get label\n        label = self.labels_to_idx[self.labels[idx]]\n        \n        # Return dictionary\n        return {\n            \"input_ids\": encoded[\"input_ids\"].squeeze(0),  # Remove batch dimension\n            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n            \"labels\": torch.tensor(label, dtype=torch.long)  # Change 'label' to 'labels'\n        }\n\n    \n    def __len__(self):\n        return len(self.sentences)\n    \n    def num_labels(self):\n        return len(self.labels_to_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:19:07.617648Z","iopub.execute_input":"2024-12-16T21:19:07.618129Z","iopub.status.idle":"2024-12-16T21:19:09.051007Z","shell.execute_reply.started":"2024-12-16T21:19:07.618089Z","shell.execute_reply":"2024-12-16T21:19:09.050355Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# Load pre-trained model and tokenizer\nmodel_name = \"5CD-AI/Vietnamese-Sentiment-visobert\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:19:09.051970Z","iopub.execute_input":"2024-12-16T21:19:09.052369Z","iopub.status.idle":"2024-12-16T21:19:32.960235Z","shell.execute_reply.started":"2024-12-16T21:19:09.052340Z","shell.execute_reply":"2024-12-16T21:19:32.959375Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/958 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9a7d155721c495f92321b9652e0e4a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/390M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1566f12421284e47a573e9c3ed35a042"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0ea8cacaf24474a5d738e5b39005cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/471k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fccba12a2214dd695120fe517b591e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a32b615553d42d886f978f8ca984929"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a4a1f6d40b84081adeb5b2f5766feae"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_dataset = BookReviews(\n    path='/kaggle/input/new-data/new_data/train.json',\n    tokenizer=tokenizer\n)\ntest_dataset = BookReviews(\n    path='/kaggle/input/new-data/new_data/test.json',\n    tokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:19:32.961914Z","iopub.execute_input":"2024-12-16T21:19:32.962428Z","iopub.status.idle":"2024-12-16T21:19:33.507665Z","shell.execute_reply.started":"2024-12-16T21:19:32.962399Z","shell.execute_reply":"2024-12-16T21:19:33.506958Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 8\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ndev_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:19:33.508609Z","iopub.execute_input":"2024-12-16T21:19:33.508933Z","iopub.status.idle":"2024-12-16T21:19:33.513924Z","shell.execute_reply.started":"2024-12-16T21:19:33.508896Z","shell.execute_reply":"2024-12-16T21:19:33.512952Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"for batch in train_dataloader:\n    print(batch[\"input_ids\"].shape)  # (batch_size, max_length)\n    print(batch[\"attention_mask\"].shape)  # (batch_size, max_length)\n    print(batch[\"labels\"].shape)  # (batch_size,)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:19:33.514885Z","iopub.execute_input":"2024-12-16T21:19:33.515174Z","iopub.status.idle":"2024-12-16T21:19:33.551115Z","shell.execute_reply.started":"2024-12-16T21:19:33.515149Z","shell.execute_reply":"2024-12-16T21:19:33.550352Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 512])\ntorch.Size([8, 512])\ntorch.Size([8])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import AdamW, get_scheduler\n\noptimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n\n# Scheduler\nnum_training_steps = len(train_dataloader) * 1  # 5 epochs\nscheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=2,\n    num_training_steps=num_training_steps\n)\nnum_epochs = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:19:33.551963Z","iopub.execute_input":"2024-12-16T21:19:33.552184Z","iopub.status.idle":"2024-12-16T21:19:33.569598Z","shell.execute_reply.started":"2024-12-16T21:19:33.552160Z","shell.execute_reply":"2024-12-16T21:19:33.568799Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport json\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nnum_epochs = 5\ntrain_metrics = []\nval_metrics = []\nbest_val_accuracy = 0  # Initialize best validation accuracy\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    total_correct_train = 0\n    total_train_samples = 0\n    loop = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n    \n    for batch in loop:\n        # Move batch to GPU\n        batch = {k: v.to(device) for k, v in batch.items()}\n        \n        # Forward pass\n        outputs = model(**batch)\n        loss = outputs.loss\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        \n        # Compute training accuracy\n        predictions = torch.argmax(outputs.logits, dim=-1)\n        total_correct_train += (predictions == batch[\"labels\"]).sum().item()\n        total_train_samples += batch[\"labels\"].size(0)\n        \n        # Update progress bar\n        loop.set_postfix(loss=loss.item())\n    \n    train_accuracy = total_correct_train / total_train_samples\n    avg_train_loss = total_loss / len(train_dataloader)\n    \n    # Evaluate on dev set\n    model.eval()\n    total_correct_val = 0\n    total_val_samples = 0\n    total_val_loss = 0\n    \n    with torch.no_grad():\n        for batch in dev_dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n            total_val_loss += loss.item()\n            predictions = torch.argmax(outputs.logits, dim=-1)\n            total_correct_val += (predictions == batch[\"labels\"]).sum().item()\n            total_val_samples += batch[\"labels\"].size(0)\n    \n    val_accuracy = total_correct_val / total_val_samples\n    avg_val_loss = total_val_loss / len(dev_dataloader)\n    \n    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss}, Train Accuracy: {train_accuracy}\")\n    print(f\"Validation Accuracy: {val_accuracy}, Validation Loss: {avg_val_loss}\")\n    \n    # Save metrics for each epoch\n    train_metrics.append({'epoch': epoch+1, 'train_loss': avg_train_loss, 'train_accuracy': train_accuracy})\n    val_metrics.append({'epoch': epoch+1, 'val_loss': avg_val_loss, 'val_accuracy': val_accuracy})\n    \n    # Save model if current validation accuracy is higher than best\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        torch.save({\n            'epoch': epoch+1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'train_metrics': train_metrics,\n            'val_metrics': val_metrics\n        }, 'best_model_checkpoint.pt')\n        print(f\"New best model saved at epoch {epoch+1} with validation accuracy: {val_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T21:19:33.570512Z","iopub.execute_input":"2024-12-16T21:19:33.570748Z","iopub.status.idle":"2024-12-16T22:29:26.036153Z","shell.execute_reply.started":"2024-12-16T21:19:33.570724Z","shell.execute_reply":"2024-12-16T22:29:26.035308Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 1744/1744 [13:02<00:00,  2.23it/s, loss=0.418] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Train Loss: 0.5798992055058138, Train Accuracy: 0.7505555157336392\nValidation Accuracy: 0.7841788478073947, Validation Loss: 0.5149136363641621\nNew best model saved at epoch 1 with validation accuracy: 0.7841788478073947\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 1744/1744 [13:03<00:00,  2.23it/s, loss=0.192] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Train Loss: 0.38201687637921594, Train Accuracy: 0.8614436241129668\nValidation Accuracy: 0.7841788478073947, Validation Loss: 0.5149136363641621\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 1744/1744 [13:04<00:00,  2.22it/s, loss=0.447] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Train Loss: 0.38344162916380126, Train Accuracy: 0.8620887391584833\nValidation Accuracy: 0.7841788478073947, Validation Loss: 0.5149136363641621\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 1744/1744 [13:04<00:00,  2.22it/s, loss=0.145] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Train Loss: 0.38560433373273856, Train Accuracy: 0.8593649200774138\nValidation Accuracy: 0.7841788478073947, Validation Loss: 0.5149136363641621\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 1744/1744 [13:04<00:00,  2.22it/s, loss=0.141] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Train Loss: 0.38433531867212045, Train Accuracy: 0.8583614077843882\nValidation Accuracy: 0.7841788478073947, Validation Loss: 0.5149136363641621\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import precision_recall_fscore_support, classification_report\n\nmodel.eval()\ntotal_correct_val = 0\ntotal_val_samples = 0\ntotal_val_loss = 0\n\n# Lists to store all true labels and predictions for calculating metrics\nall_true_labels = []\nall_predictions = []\n\nwith torch.no_grad():\n    for batch in dev_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        total_val_loss += loss.item()\n        predictions = torch.argmax(outputs.logits, dim=-1)\n        total_correct_val += (predictions == batch[\"labels\"]).sum().item()\n        total_val_samples += batch[\"labels\"].size(0)\n\n        # Store true labels and predictions\n        all_true_labels.extend(batch[\"labels\"].cpu().numpy())\n        all_predictions.extend(predictions.cpu().numpy())\n\nval_accuracy = total_correct_val / total_val_samples\navg_val_loss = total_val_loss / len(dev_dataloader)\n\n# Calculate precision, recall, and F1-score\nprecision, recall, f1_score, _ = precision_recall_fscore_support(all_true_labels, all_predictions, average='weighted')\n\n# Generate classification report\nclass_report = classification_report(all_true_labels, all_predictions)\n\nprint(f\"Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {avg_val_loss:.4f}\")\nprint(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1_score:.4f}\")\nprint(\"\\nClassification Report:\")\nprint(class_report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T22:29:26.037731Z","iopub.execute_input":"2024-12-16T22:29:26.038097Z","iopub.status.idle":"2024-12-16T22:30:20.778836Z","shell.execute_reply.started":"2024-12-16T22:29:26.038058Z","shell.execute_reply":"2024-12-16T22:30:20.778012Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.7842, Validation Loss: 0.5149\nPrecision: 0.7804, Recall: 0.7842, F1-Score: 0.7817\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.77      0.78      0.78       795\n           1       0.84      0.88      0.86      1736\n           2       0.68      0.62      0.65       958\n\n    accuracy                           0.78      3489\n   macro avg       0.76      0.76      0.76      3489\nweighted avg       0.78      0.78      0.78      3489\n\n","output_type":"stream"}],"execution_count":9}]}